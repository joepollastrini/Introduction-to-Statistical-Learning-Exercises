{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8) We will generate simulated data and use it to perform best subset selection\n",
    "\n",
    "a) Create a dataset of n = 100 with a predictor, X, from a random normal distribution and a noise term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "x = np.random.normal(0, 1, 100)\n",
    "error = np.random.normal(0, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "b0 = 1.4\n",
    "b1 = 0.5\n",
    "b2 = -0.1\n",
    "b3 = 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) generate a response variable, Y, such that Y = B0 + B1X + B2X^2 + B3X^3 + error, and the Beta terms are constants of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'X':x, 'error':error}, columns = ['X', 'error'])\n",
    "for i in range(2, 11):\n",
    "    col_name = 'X' + str(i)\n",
    "    df[col_name] = df['X'].apply(lambda x: x**i)\n",
    "df['Y'] = df.apply(lambda row: b0 + b1*row['X'] + b2*row['X2'] + b3*row['X3'] + row['error'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Use best subset selection to choose the best model from the predictors X, X^2, ..., X^10.  What is the best model according to Cp, BIC, and adjusted R^2.  Show plots to provide evidence and report the coefficients of the best model obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(x, y):\n",
    "    model = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "    BIC = model.bic\n",
    "    adj = model.rsquared_adj\n",
    "    return BIC, adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "Y = df['Y']\n",
    "X = df.drop(columns = ['error', 'Y'], axis=1)\n",
    "k = X.shape[1]\n",
    "\n",
    "BIC_data = []\n",
    "R2_data = []\n",
    "features = []\n",
    "numb_features = []\n",
    "\n",
    "for i in range(1, k + 1):\n",
    "    for combo in itertools.combinations(X.columns, i):\n",
    "        mod = model_fit(X[list(combo)], Y)\n",
    "        BIC_data.append(mod[0])\n",
    "        R2_data.append(mod[1])\n",
    "        features.append(list(combo))\n",
    "        numb_features.append(i)\n",
    "        \n",
    "bestSubset = pd.DataFrame({'BIC':BIC_data, 'R2':R2_data, 'Feats':features, '#':numb_features})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_bic = bestSubset.groupby('#')['BIC'].min()\n",
    "best_r2 = bestSubset.groupby('#')['R2'].max()\n",
    "\n",
    "avg_bic = bestSubset.groupby('#')['BIC'].mean()\n",
    "avg_r2 = bestSubset.groupby('#')['R2'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize = (10, 6))\n",
    "\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.set_title('Best BIC')\n",
    "best_bic.plot();\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.set_title('Best Adjusted R^2')\n",
    "best_r2.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 variables seems to be the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['X2', 'X3', 'X5']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestGrouped = bestSubset[bestSubset.groupby('#')['BIC'].transform(min) == bestSubset['BIC']]\n",
    "bestCols = bestGrouped.loc[bestGrouped['#'] == 3]\n",
    "x_cols = list(bestCols['Feats'])\n",
    "x_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "const    1.586906\n",
       "X2      -0.229213\n",
       "X3       1.727621\n",
       "X5      -0.080601\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = df[x_cols[0]]\n",
    "y_data = df['Y']\n",
    "model = sm.OLS(y_data, sm.add_constant(x_data)).fit()\n",
    "model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Repeat c, using forward stepwise selection and using backwards selection.  How do the results compare to c?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns = ['error', 'Y'])\n",
    "y = df['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.952\n",
      "Model:                            OLS   Adj. R-squared:                  0.947\n",
      "Method:                 Least Squares   F-statistic:                     176.9\n",
      "Date:                Wed, 12 Aug 2020   Prob (F-statistic):           3.17e-54\n",
      "Time:                        14:14:31   Log-Likelihood:                -139.57\n",
      "No. Observations:                 100   AIC:                             301.1\n",
      "Df Residuals:                      89   BIC:                             329.8\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.7798      0.220      8.094      0.000       1.343       2.217\n",
      "X              0.3975      0.621      0.640      0.524      -0.836       1.631\n",
      "X2            -1.4865      1.593     -0.933      0.353      -4.651       1.678\n",
      "X3             0.4009      1.543      0.260      0.796      -2.664       3.466\n",
      "X4             1.1357      2.578      0.441      0.661      -3.987       6.258\n",
      "X5             1.2123      1.176      1.031      0.305      -1.124       3.548\n",
      "X6            -0.3210      1.504     -0.213      0.832      -3.310       2.668\n",
      "X7            -0.4224      0.336     -1.259      0.211      -1.089       0.244\n",
      "X8             0.0219      0.355      0.062      0.951      -0.683       0.727\n",
      "X9             0.0416      0.032      1.319      0.190      -0.021       0.104\n",
      "X10            0.0018      0.029      0.063      0.950      -0.055       0.059\n",
      "==============================================================================\n",
      "Omnibus:                       12.606   Durbin-Watson:                   1.988\n",
      "Prob(Omnibus):                  0.002   Jarque-Bera (JB):                5.096\n",
      "Skew:                           0.286   Prob(JB):                       0.0782\n",
      "Kurtosis:                       2.053   Cond. No.                     4.43e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.43e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "model = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.952\n",
      "Model:                            OLS   Adj. R-squared:                  0.947\n",
      "Method:                 Least Squares   F-statistic:                     198.7\n",
      "Date:                Wed, 12 Aug 2020   Prob (F-statistic):           2.18e-55\n",
      "Time:                        14:14:31   Log-Likelihood:                -139.57\n",
      "No. Observations:                 100   AIC:                             299.1\n",
      "Df Residuals:                      90   BIC:                             325.2\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.7861      0.195      9.176      0.000       1.399       2.173\n",
      "X              0.3911      0.609      0.642      0.522      -0.819       1.601\n",
      "X2            -1.5677      0.920     -1.704      0.092      -3.395       0.260\n",
      "X3             0.4260      1.482      0.287      0.774      -2.518       3.369\n",
      "X4             1.2857      0.947      1.358      0.178      -0.595       3.166\n",
      "X5             1.1866      1.096      1.083      0.282      -0.990       3.363\n",
      "X6            -0.4131      0.317     -1.304      0.196      -1.042       0.216\n",
      "X7            -0.4132      0.300     -1.376      0.172      -1.010       0.183\n",
      "X8             0.0441      0.032      1.358      0.178      -0.020       0.109\n",
      "X9             0.0405      0.027      1.526      0.131      -0.012       0.093\n",
      "==============================================================================\n",
      "Omnibus:                       12.679   Durbin-Watson:                   1.985\n",
      "Prob(Omnibus):                  0.002   Jarque-Bera (JB):                5.114\n",
      "Skew:                           0.286   Prob(JB):                       0.0775\n",
      "Kurtosis:                       2.052   Cond. No.                     1.02e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.02e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "x = x.drop(columns=['X10'])\n",
    "model = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.952\n",
      "Model:                            OLS   Adj. R-squared:                  0.948\n",
      "Method:                 Least Squares   F-statistic:                     225.8\n",
      "Date:                Wed, 12 Aug 2020   Prob (F-statistic):           1.46e-56\n",
      "Time:                        14:14:31   Log-Likelihood:                -139.62\n",
      "No. Observations:                 100   AIC:                             297.2\n",
      "Df Residuals:                      91   BIC:                             320.7\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.7853      0.194      9.219      0.000       1.401       2.170\n",
      "X              0.5478      0.270      2.027      0.046       0.011       1.085\n",
      "X2            -1.5976      0.909     -1.757      0.082      -3.404       0.209\n",
      "X4             1.3372      0.925      1.446      0.152      -0.500       3.174\n",
      "X5             1.4924      0.260      5.738      0.000       0.976       2.009\n",
      "X6            -0.4363      0.305     -1.432      0.156      -1.042       0.169\n",
      "X7            -0.4930      0.114     -4.330      0.000      -0.719      -0.267\n",
      "X8             0.0472      0.030      1.548      0.125      -0.013       0.108\n",
      "X9             0.0473      0.012      3.806      0.000       0.023       0.072\n",
      "==============================================================================\n",
      "Omnibus:                       12.493   Durbin-Watson:                   1.994\n",
      "Prob(Omnibus):                  0.002   Jarque-Bera (JB):                5.132\n",
      "Skew:                           0.293   Prob(JB):                       0.0768\n",
      "Kurtosis:                       2.057   Cond. No.                     6.94e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 6.94e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "x = x.drop(columns=['X3'])\n",
    "model = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.951\n",
      "Model:                            OLS   Adj. R-squared:                  0.947\n",
      "Method:                 Least Squares   F-statistic:                     254.9\n",
      "Date:                Wed, 12 Aug 2020   Prob (F-statistic):           2.42e-57\n",
      "Time:                        14:14:31   Log-Likelihood:                -140.73\n",
      "No. Observations:                 100   AIC:                             297.5\n",
      "Df Residuals:                      92   BIC:                             318.3\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.6482      0.169      9.738      0.000       1.312       1.984\n",
      "X              0.6230      0.267      2.337      0.022       0.094       1.152\n",
      "X2            -0.4322      0.408     -1.060      0.292      -1.242       0.378\n",
      "X4             0.0344      0.165      0.208      0.835      -0.294       0.363\n",
      "X5             1.3872      0.251      5.529      0.000       0.889       1.886\n",
      "X7            -0.4417      0.109     -4.064      0.000      -0.658      -0.226\n",
      "X8             0.0039      0.004      0.971      0.334      -0.004       0.012\n",
      "X9             0.0407      0.012      3.507      0.001       0.018       0.064\n",
      "==============================================================================\n",
      "Omnibus:                       11.963   Durbin-Watson:                   2.022\n",
      "Prob(Omnibus):                  0.003   Jarque-Bera (JB):                4.474\n",
      "Skew:                           0.210   Prob(JB):                        0.107\n",
      "Kurtosis:                       2.052   Cond. No.                     2.38e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.38e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "x = x.drop(columns=['X6'])\n",
    "model = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.951\n",
      "Model:                            OLS   Adj. R-squared:                  0.948\n",
      "Method:                 Least Squares   F-statistic:                     300.5\n",
      "Date:                Wed, 12 Aug 2020   Prob (F-statistic):           1.36e-58\n",
      "Time:                        14:14:31   Log-Likelihood:                -140.76\n",
      "No. Observations:                 100   AIC:                             295.5\n",
      "Df Residuals:                      93   BIC:                             313.8\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.6291      0.142     11.504      0.000       1.348       1.910\n",
      "X              0.6163      0.263      2.341      0.021       0.094       1.139\n",
      "X2            -0.3516      0.128     -2.754      0.007      -0.605      -0.098\n",
      "X5             1.3985      0.244      5.737      0.000       0.914       1.883\n",
      "X7            -0.4471      0.105     -4.253      0.000      -0.656      -0.238\n",
      "X8             0.0047      0.002      2.496      0.014       0.001       0.008\n",
      "X9             0.0414      0.011      3.711      0.000       0.019       0.064\n",
      "==============================================================================\n",
      "Omnibus:                       12.423   Durbin-Watson:                   2.010\n",
      "Prob(Omnibus):                  0.002   Jarque-Bera (JB):                4.606\n",
      "Skew:                           0.219   Prob(JB):                        0.100\n",
      "Kurtosis:                       2.044   Cond. No.                     1.85e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.85e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "x = x.drop(columns=['X4'])\n",
    "model = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method keeps many more variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const    1.629131\n",
       "X        0.616345\n",
       "X2      -0.351628\n",
       "X5       1.398493\n",
       "X7      -0.447058\n",
       "X8       0.004660\n",
       "X9       0.041387\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns = ['error', 'Y'])\n",
    "y = df['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: 457.2140941321456, 0.7380986215327766\n",
      "X2: 592.0914908171761, -0.009027204349405515\n",
      "X3: 312.4348926817268, 0.9384299223351408\n",
      "X4: 592.1270502222935, -0.009386072222604902\n",
      "X5: 436.0502089595571, 0.7880545006448726\n",
      "X6: 590.7685542038417, 0.004233676049315571\n",
      "X7: 493.5752082675984, 0.6232510101852304\n",
      "X8: 587.9759650109153, 0.03165665113952765\n",
      "X9: 520.5260686816937, 0.5067146744258382\n",
      "X10: 584.5522401120544, 0.0642489446151221\n"
     ]
    }
   ],
   "source": [
    "for c in x.columns:\n",
    "    x_data = x[c]\n",
    "    model = sm.OLS(y, sm.add_constant(x_data)).fit()\n",
    "    bic = model.bic\n",
    "    adj = model.rsquared_adj\n",
    "    print('{}: {}, {}'.format(c, bic, adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X3', 'X']: 306.7369727015427, 0.9438850874065042\n",
      "['X3', 'X2']: 313.79654117125204, 0.9397804359623894\n",
      "['X3', 'X4']: 316.04803340515, 0.9384092186536857\n",
      "['X3', 'X5']: 307.31602634746724, 0.9435592093654508\n",
      "['X3', 'X6']: 316.8558228543487, 0.9379096799260609\n",
      "['X3', 'X7']: 309.7669068568319, 0.9421588222188302\n",
      "['X3', 'X8']: 317.03894903627037, 0.9377958721194256\n",
      "['X3', 'X9']: 311.59880754913974, 0.9410894644009435\n",
      "['X3', 'X10']: 316.9773237517707, 0.9378341937810734\n"
     ]
    }
   ],
   "source": [
    "keep_cols = ['X3']\n",
    "cols = x.columns\n",
    "x_cols = cols.drop(keep_cols)\n",
    "\n",
    "for c in x_cols:\n",
    "    cols = keep_cols + [c]\n",
    "    x_data = x[cols]\n",
    "    model = sm.OLS(y, sm.add_constant(x_data)).fit()\n",
    "    bic = model.bic\n",
    "    adj = model.rsquared_adj\n",
    "    print('{}: {}, {}'.format(cols, bic, adj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIC decreases and Adj R^2 increases when X and X3 are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X3', 'X', 'X2']: 307.0000988427286, 0.9457097884040169\n",
      "['X3', 'X', 'X4']: 309.2634530652569, 0.9444669972787478\n",
      "['X3', 'X', 'X5']: 310.1851037425038, 0.9439528111227244\n",
      "['X3', 'X', 'X6']: 310.28523640260113, 0.943896661474215\n",
      "['X3', 'X', 'X7']: 310.7510677956349, 0.9436347048464201\n",
      "['X3', 'X', 'X8']: 310.7515510412442, 0.943634432462948\n",
      "['X3', 'X', 'X9']: 311.0774509251191, 0.9434504374869447\n",
      "['X3', 'X', 'X10']: 310.98064727855865, 0.9435051530379741\n"
     ]
    }
   ],
   "source": [
    "keep_cols = ['X3', 'X']\n",
    "cols = x.columns\n",
    "x_cols = cols.drop(keep_cols)\n",
    "\n",
    "for c in x_cols:\n",
    "    cols = keep_cols + [c]\n",
    "    x_data = x[cols]\n",
    "    model = sm.OLS(y, sm.add_constant(x_data)).fit()\n",
    "    bic = model.bic\n",
    "    adj = model.rsquared_adj\n",
    "    print('{}: {}, {}'.format(cols, bic, adj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIC increases slightly, and Adj R^2 increases when X, X2, and X3 are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'X3', 'X2', 'X4']: 309.9787349697433, 0.9460234385724502\n",
      "['X', 'X3', 'X2', 'X5']: 308.10092647399046, 0.947027557804949\n",
      "['X', 'X3', 'X2', 'X6']: 310.1715561155734, 0.9459192599412887\n",
      "['X', 'X3', 'X2', 'X7']: 308.6038209152274, 0.9467604913694819\n",
      "['X', 'X3', 'X2', 'X8']: 310.21577523098244, 0.9458953406283634\n",
      "['X', 'X3', 'X2', 'X9']: 309.0154876575666, 0.9465408702753223\n",
      "['X', 'X3', 'X2', 'X10']: 310.1967599008514, 0.9459056278298557\n"
     ]
    }
   ],
   "source": [
    "keep_cols = ['X', 'X3', 'X2']\n",
    "cols = x.columns\n",
    "x_cols = cols.drop(keep_cols)\n",
    "\n",
    "for c in x_cols:\n",
    "    cols = keep_cols + [c]\n",
    "    x_data = x[cols]\n",
    "    model = sm.OLS(y, sm.add_constant(x_data)).fit()\n",
    "    bic = model.bic\n",
    "    adj = model.rsquared_adj\n",
    "    print('{}: {}, {}'.format(cols, bic, adj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIC and adj R^2 increase slightly when adding X5 to the model.  R^2 increases by 0.0013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'X3', 'X2', 'X5', 'X4']: 312.31489447941203, 0.9466730459810082\n",
      "['X', 'X3', 'X2', 'X5', 'X6']: 312.5357608729921, 0.9465551344953703\n",
      "['X', 'X3', 'X2', 'X5', 'X7']: 312.16553647662136, 0.946752634603696\n",
      "['X', 'X3', 'X2', 'X5', 'X8']: 312.6260199964898, 0.9465068738516706\n",
      "['X', 'X3', 'X2', 'X5', 'X9']: 312.193544706514, 0.9467377188704651\n",
      "['X', 'X3', 'X2', 'X5', 'X10']: 312.6686968804014, 0.9464840397802351\n"
     ]
    }
   ],
   "source": [
    "keep_cols = ['X', 'X3', 'X2', 'X5']\n",
    "cols = x.columns\n",
    "x_cols = cols.drop(keep_cols)\n",
    "\n",
    "for c in x_cols:\n",
    "    cols = keep_cols + [c]\n",
    "    x_data = x[cols]\n",
    "    model = sm.OLS(y, sm.add_constant(x_data)).fit()\n",
    "    bic = model.bic\n",
    "    adj = model.rsquared_adj\n",
    "    print('{}: {}, {}'.format(cols, bic, adj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIC increases significantly more than prior, and R^2 decreases.  The best model has X, X2, X3, and X5 as its features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const    1.577226\n",
       "X        0.230710\n",
       "X2      -0.215664\n",
       "X3       1.577513\n",
       "X5      -0.061077\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = df[['X', 'X2', 'X3', 'X5']]\n",
    "model = sm.OLS(y, sm.add_constant(x_data)).fit()\n",
    "model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Now fit a lasso model to the simulated data, using the same predictors.  Use cross validation to select the optimal lambda. Create plots of the cross validation error as a function of lambda.  Report the resulting coefficient estimates and discuss the results obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.79754915579858, tolerance: 0.1625647600549571\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.44484997575065, tolerance: 0.19320369713617133\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.155199860945864, tolerance: 0.12531217379019594\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.09602841753498, tolerance: 0.18486198808246898\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.480746834519636, tolerance: 0.17258136729624773\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.94141303734082, tolerance: 0.1962047966790703\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.487446961225736, tolerance: 0.18678003276143887\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.12135690901648, tolerance: 0.19572174276150142\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.42102091557321, tolerance: 0.18286414408055196\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.557426169409915, tolerance: 0.19096986194104162\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.79754915579867, tolerance: 0.1625647600549571\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.44484997575046, tolerance: 0.19320369713617133\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.15519986094552, tolerance: 0.12531217379019594\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.09602841753512, tolerance: 0.18486198808246898\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.480746834519714, tolerance: 0.17258136729624773\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.94141303734118, tolerance: 0.1962047966790703\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.487446961225835, tolerance: 0.18678003276143887\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.12135690901646, tolerance: 0.19572174276150142\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.42102091557312, tolerance: 0.18286414408055196\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.55742616940997, tolerance: 0.19096986194104162\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.79754916963384, tolerance: 0.1625647600549571\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.44484996384969, tolerance: 0.19320369713617133\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.15519981189344, tolerance: 0.12531217379019594\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.0960284311806, tolerance: 0.18486198808246898\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.480746847617375, tolerance: 0.17258136729624773\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.94141304679663, tolerance: 0.1962047966790703\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.48744697107925, tolerance: 0.18678003276143887\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.12135692075446, tolerance: 0.19572174276150142\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.42102091022984, tolerance: 0.18286414408055196\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.557426172267206, tolerance: 0.19096986194104162\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.798930468467894, tolerance: 0.1625647600549571\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.443653007255655, tolerance: 0.19320369713617133\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.15028893959244, tolerance: 0.12531217379019594\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.09739035003208, tolerance: 0.18486198808246898\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.48205406805892, tolerance: 0.17258136729624773\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.94235535494989, tolerance: 0.1962047966790703\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.48843043148558, tolerance: 0.18678003276143887\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.12252785564577, tolerance: 0.19572174276150142\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.420483158355914, tolerance: 0.18286414408055196\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.557707778462564, tolerance: 0.19096986194104162\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.81116133361779, tolerance: 0.1625647600549571\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.4322513345846, tolerance: 0.19320369713617133\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.105578731050244, tolerance: 0.12531217379019594\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.109409027862164, tolerance: 0.18486198808246898\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.49358213186664, tolerance: 0.17258136729624773\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.95054196397975, tolerance: 0.1962047966790703\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.49710948450092, tolerance: 0.18678003276143887\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.132806090355906, tolerance: 0.19572174276150142\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.41533329960634, tolerance: 0.18286414408055196\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.55986609283306, tolerance: 0.19096986194104162\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.91256697946339, tolerance: 0.1625647600549571\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.24643253674123, tolerance: 0.19320369713617133\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.617596546774884, tolerance: 0.12531217379019594\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.20496491542478, tolerance: 0.18486198808246898\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.58446608104855, tolerance: 0.17258136729624773\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.001817616541594, tolerance: 0.1962047966790703\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.56625011523755, tolerance: 0.18678003276143887\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.208682238675244, tolerance: 0.19572174276150142\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.33111282716877, tolerance: 0.18286414408055196\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.54139430111614, tolerance: 0.19096986194104162\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 34.91899268780692, tolerance: 0.1625647600549571\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.89666480563831, tolerance: 0.19320369713617133\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 30.25600682794244, tolerance: 0.12531217379019594\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.94920358519293, tolerance: 0.18486198808246898\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.04341569968866, tolerance: 0.17258136729624773\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.41365584134622, tolerance: 0.1962047966790703\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.11834378649724, tolerance: 0.18678003276143887\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.41062860306995, tolerance: 0.19572174276150142\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 35.235758710447136, tolerance: 0.18286414408055196\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.82047941180809, tolerance: 0.19096986194104162\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.66099938822638, tolerance: 0.1625647600549571\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.884369203434957, tolerance: 0.19320369713617133\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 22.201234944121737, tolerance: 0.12531217379019594\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.595709927968002, tolerance: 0.17258136729624773\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.41448856571246, tolerance: 0.1962047966790703\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.636412164335695, tolerance: 0.18678003276143887\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.681340800162872, tolerance: 0.19572174276150142\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14.440628048468817, tolerance: 0.19096986194104162\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4089724088096318, tolerance: 0.19320369713617133\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 24.786246197255522, tolerance: 0.18486198808246898\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6799904709029647, tolerance: 0.1962047966790703\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5376161539977886, tolerance: 0.19572174276150142\n",
      "  positive)\n",
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4017325785765422, tolerance: 0.19096986194104162\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV as gscv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "x = df.drop(columns = ['error', 'Y'])\n",
    "y = df['Y']\n",
    "lambdas = [1e-20, 1e-15, 1e-10, .00001, .0001, .001, .01, .1, 1, 5]\n",
    "score_dict = {}\n",
    "for alpha in lambdas:\n",
    "    lasso = Lasso(alpha = alpha)\n",
    "    scores = cross_val_score(lasso, x, y, scoring = 'neg_mean_squared_error', cv=10)\n",
    "    score_dict[alpha] = (scores.mean(), scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scoreDF = pd.DataFrame.from_dict(score_dict, orient='index', columns = ['Mean', 'Std'])\n",
    "scoreDF.reset_index(inplace=True)\n",
    "scoreDF.rename(columns={'index':'lambda'}, inplace=True)\n",
    "scoreDF['Log'] = np.log(scoreDF['lambda'])\n",
    "scoreDF['Mean'] = scoreDF['Mean'].apply(lambda x: x*-1)\n",
    "scoreDF.plot(x='Log', y='Mean', kind='scatter');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 48.978041392685185, tolerance: 0.1992748843178194\n",
      "  positive)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.03573039198900109,\n",
       " -0.7832556523336743,\n",
       " 2.043446447655669,\n",
       " 0.3202593567440675,\n",
       " -0.2053968103872179,\n",
       " -0.04369417413855734,\n",
       " -0.005900438241495714,\n",
       " -0.002538286028620221,\n",
       " 0.003286277398447138,\n",
       " 0.0007630924101340264]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = scoreDF['Mean'].min()\n",
    "bestLambda = scoreDF[scoreDF['Mean'] == best]['lambda'].values[0]\n",
    "lasso = Lasso(alpha = bestLambda)\n",
    "lasso.fit(x, y)\n",
    "list(lasso.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These coefficients aren't anything close to the actual coefficients.  The lasso seemed to be best as lambda approached 0 (normal linear regression), which shouldn't be the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Now generate a response vector Y according to Y = B0 + B7X^7 + error and perform best subset selection and the lasso.  Discuss results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "b7 = 2.5\n",
    "df2['Y'] = df.apply(lambda row: b0 + b7*row['X7'] + row['error'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "Y = df2['Y']\n",
    "X = df2.drop(columns = ['error', 'Y'], axis=1)\n",
    "k = X.shape[1]\n",
    "\n",
    "BIC_data = []\n",
    "R2_data = []\n",
    "features = []\n",
    "numb_features = []\n",
    "\n",
    "for i in range(1, k + 1):\n",
    "    for combo in itertools.combinations(X.columns, i):\n",
    "        mod = model_fit(X[list(combo)], Y)\n",
    "        BIC_data.append(mod[0])\n",
    "        R2_data.append(mod[1])\n",
    "        features.append(list(combo))\n",
    "        numb_features.append(i)\n",
    "        \n",
    "bestSubset = pd.DataFrame({'BIC':BIC_data, 'R2':R2_data, 'Feats':features, '#':numb_features})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_bic = bestSubset.groupby('#')['BIC'].min()\n",
    "best_r2 = bestSubset.groupby('#')['R2'].max()\n",
    "\n",
    "avg_bic = bestSubset.groupby('#')['BIC'].mean()\n",
    "avg_r2 = bestSubset.groupby('#')['R2'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize = (10, 6))\n",
    "\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.set_title('Best BIC')\n",
    "best_bic.plot();\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.set_title('Best Adjusted R^2')\n",
    "best_r2.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['X7']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestGrouped = bestSubset[bestSubset.groupby('#')['BIC'].transform(min) == bestSubset['BIC']]\n",
    "bestCols = bestGrouped.loc[bestGrouped['#'] == 1]\n",
    "x_cols = list(bestCols['Feats'])\n",
    "x_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "const    1.482050\n",
       "X7       2.499915\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = df2[x_cols[0]]\n",
    "y_data = df2['Y']\n",
    "model = sm.OLS(y_data, sm.add_constant(x_data)).fit()\n",
    "model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['X', 'X2', 'X4', 'X6', 'X8', 'X10']]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestGrouped = bestSubset[bestSubset.groupby('#')['R2'].transform(min) == bestSubset['R2']]\n",
    "bestCols = bestGrouped.loc[bestGrouped['#'] == 6]\n",
    "x_cols = list(bestCols['Feats'])\n",
    "x_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost exactly what the estimated coefficient was.  Interestingly, the best using adjusted r-squared does not include the explanatory variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.01}\n",
      "-44.947516411665156\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV as gscv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "x = df2.drop(columns = ['error', 'Y'])\n",
    "y = df2['Y']\n",
    "lasso = Lasso()\n",
    "parameters = {'alpha':[1e-20, 1e-15, 1e-10, .00001, .0001, .001, .01, .1, 1, 5]}\n",
    "lasso_regressor = gscv(lasso, parameters, scoring='neg_mean_squared_error', cv=5)\n",
    "lasso_regressor.fit(x, y)\n",
    "print(lasso_regressor.best_params_)\n",
    "print(lasso_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.018706918672408,\n",
       " -2.5079469838045223,\n",
       " -6.479325081614762,\n",
       " 2.378695623086458,\n",
       " 5.178688675390131,\n",
       " -0.6141909855572703,\n",
       " 1.0614225756582887,\n",
       " -0.0011466160442400485,\n",
       " 0.12769437312223936,\n",
       " 0.010015991689610567]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso(alpha = lasso_regressor.best_params_['alpha'])\n",
    "lasso.fit(x, y)\n",
    "list(lasso.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, these results are not anywhere close to what they should be.  Likely doing lasso incorrectly here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9)  We will predict the number of applicatoins received using the other variables in the college data set\n",
    "\n",
    "a) Split the data set into a training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "path = os.path.join(os.getcwd(), 'College.csv')\n",
    "college = pd.read_csv(path)\n",
    "college.rename(columns={'Unnamed: 0':'College'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "college['Private_IO'] = college['Private'].apply(lambda x: 1 if x=='Yes' else 0)\n",
    "colDrop = ['Private']\n",
    "college.drop(columns = colDrop, inplace=True)\n",
    "\n",
    "y_col = 'Apps'\n",
    "forTT = college.drop(columns = [y_col, 'College'])\n",
    "x_cols = forTT.columns\n",
    "x_train, x_test, y_train, y_test = tts(college[x_cols], college[y_col], random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Fit a linear model using least squares on the training set, and report the test error obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1022430.0889255457"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression as linreg\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "model = linreg()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "mse(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Fit a ridge regression model on the training set, with lambda chosen by cross-validation.  Report the test error obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 40}\n",
      "1498298.063694811\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge()\n",
    "params = {'alpha':[30, 35, 40, 45, 50, 55, 60]}\n",
    "ridge_regressor = gscv(ridge, params, scoring = 'neg_mean_squared_error', cv=5)\n",
    "ridge_regressor.fit(x_train, y_train)\n",
    "\n",
    "print(ridge_regressor.best_params_)\n",
    "print(ridge_regressor.best_score_ * -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1017555.9270697526"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Ridge(alpha = ridge_regressor.best_params_['alpha'])\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "mse(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Fit a lasso model on the training set, using CV to choose lambda.  Report the test error obtained and the number of non-zero coefficient estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 180}\n",
      "1497496.549591384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "params = {'alpha':[150, 160, 165, 170, 175, 180, 185, 190, 195, 200]}\n",
    "lasso_regressor = gscv(lasso, params, scoring = 'neg_mean_squared_error', cv=5)\n",
    "lasso_regressor.fit(x_train, y_train)\n",
    "\n",
    "print(lasso_regressor.best_params_)\n",
    "print(lasso_regressor.best_score_ * -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1019713.8097130827"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Lasso(alpha = lasso_regressor.best_params_['alpha'])\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "mse(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.6298424015335762,\n",
       " -1.0240542069962795,\n",
       " 51.27756631920167,\n",
       " -13.353063411600663,\n",
       " 0.08567855128586946,\n",
       " 0.058143459881948585,\n",
       " -0.10419435612206884,\n",
       " 0.1535757007611232,\n",
       " -0.011155953377862854,\n",
       " -0.01862001020990704,\n",
       " -7.696251372107008,\n",
       " -0.30574971308694227,\n",
       " 0.0,\n",
       " -0.0,\n",
       " 0.050072342084938305,\n",
       " 5.975325833094307,\n",
       " -0.0]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All but 3 variables are non-zero, with an additional 5 variables with a coefficient less than 0.1 (absolute value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) e, but use PLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression as PLS\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_components': 9}\n",
      "1502225.1394760227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "pls = PLS()\n",
    "\n",
    "params = {'n_components':range(1, len(x_train.columns))}\n",
    "pls_regressor = gscv(pls, params, scoring = 'neg_mean_squared_error', cv=5)\n",
    "pls_regressor.fit(x_train, y_train)\n",
    "\n",
    "print(pls_regressor.best_params_)\n",
    "print(pls_regressor.best_score_ * -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1022578.3870499638"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PLS(n_components = pls_regressor.best_params_['n_components'])\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "mse(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) Comment on these 5 approaches and their accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LogReg - 1022430\n",
    "* Ridge - 1017555\n",
    "* Lasso - 1019713\n",
    "* PCR - 1022578\n",
    "\n",
    "Ridge and lasso improved on the initial model, ridge outperforming lasso by a small margin (0.002%).  PCR was about the same, as the initial model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
